{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Data 620, Week 5, Part 2 Assignment\n",
    " #### Team 4: John Grando, Nick Capofari, Ken Markus, Armenoush Aslanian-Persico, Andrew Goldberg\n",
    " \n",
    " #### Project Details: \n",
    "Use a dataset to predict a class of new documents (either withheld from the training dataset or from another source such as your own spam folder). \n",
    "\n",
    "For this project, we used a pre-processed Enron e-mail corpus (available here: http://www2.aueb.gr/users/ion/data/enron-spam/) to classify the documents as either spam or ham. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Import and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from IPython.display import display\n",
    "\n",
    "spamfolder = '/Users/andrew/Documents/School/Web Analytics/HW4/enron1/spam'\n",
    "spamdata = []\n",
    "for filename in os.listdir(spamfolder):\n",
    "    with open(spamfolder+'/'+filename) as spamtext:\n",
    "        spamtext = spamtext.read()\n",
    "        spamtext = spamtext.decode('UTF8', errors='ignore')\n",
    "        spamdata.append(spamtext)\n",
    "        \n",
    "hamfolder = '/Users/andrew/Documents/School/Web Analytics/HW4/enron1/ham'\n",
    "hamdata = []\n",
    "for filename in os.listdir(hamfolder):\n",
    "    with open(hamfolder+'/'+filename) as hamtext:\n",
    "        hamtext = hamtext.read()\n",
    "        hamtext = hamtext.decode('UTF8', errors='ignore')\n",
    "        hamdata.append(hamtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Subject: vastar resources , inc .\\r\\ngary , production from the high island larger block a - 1 # 2 commenced on\\r\\nsaturday at 2 : 00 p . m . at about 6 , 500 gross . carlos expects between 9 , 500 and\\r\\n10 , 000 gross for tomorrow . vastar owns 68 % of the gross production .\\r\\ngeorge x 3 - 6992\\r\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by george weissman / hou / ect on 12 / 13 / 99 10 : 16\\r\\nam - - - - - - - - - - - - - - - - - - - - - - - - - - -\\r\\ndaren j farmer\\r\\n12 / 10 / 99 10 : 38 am\\r\\nto : carlos j rodriguez / hou / ect @ ect\\r\\ncc : george weissman / hou / ect @ ect , melissa graves / hou / ect @ ect\\r\\nsubject : vastar resources , inc .\\r\\ncarlos ,\\r\\nplease call linda and get everything set up .\\r\\ni \\' m going to estimate 4 , 500 coming up tomorrow , with a 2 , 000 increase each\\r\\nfollowing day based on my conversations with bill fischer at bmar .\\r\\nd .\\r\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by daren j farmer / hou / ect on 12 / 10 / 99 10 : 34\\r\\nam - - - - - - - - - - - - - - - - - - - - - - - - - - -\\r\\nenron north america corp .\\r\\nfrom : george weissman 12 / 10 / 99 10 : 00 am\\r\\nto : daren j farmer / hou / ect @ ect\\r\\ncc : gary bryan / hou / ect @ ect , melissa graves / hou / ect @ ect\\r\\nsubject : vastar resources , inc .\\r\\ndarren ,\\r\\nthe attached appears to be a nomination from vastar resources , inc . for the\\r\\nhigh island larger block a - 1 # 2 ( previously , erroneously referred to as the\\r\\n# 1 well ) . vastar now expects the well to commence production sometime\\r\\ntomorrow . i told linda harris that we \\' d get her a telephone number in gas\\r\\ncontrol so she can provide notification of the turn - on tomorrow . linda \\' s\\r\\nnumbers , for the record , are 281 . 584 . 3359 voice and 713 . 312 . 1689 fax .\\r\\nwould you please see that someone contacts linda and advises her how to\\r\\nsubmit future nominations via e - mail , fax or voice ? thanks .\\r\\ngeorge x 3 - 6992\\r\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by george weissman / hou / ect on 12 / 10 / 99 09 : 44\\r\\nam - - - - - - - - - - - - - - - - - - - - - - - - - - -\\r\\n\" linda harris \" on 12 / 10 / 99 09 : 38 : 43 am\\r\\nto : george weissman / hou / ect @ ect\\r\\ncc :\\r\\nsubject : hi a - 1 # 2\\r\\neffective 12 - 11 - 99\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| mscf / d | min ftp | time |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 4 , 500 | 9 , 925 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 6 , 000 | 9 , 908 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 8 , 000 | 9 , 878 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 10 , 000 | 9 , 840 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 12 , 000 | 9 , 793 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 14 , 000 | 9 , 738 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 16 , 000 | 9 , 674 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 18 , 000 | 9 , 602 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 20 , 000 | 9 , 521 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 22 , 000 | 9 , 431 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 24 , 000 | 9 , 332 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 26 , 000 | 9 , 224 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 28 , 000 | 9 , 108 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 30 , 000 | 8 , 982 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 32 , 000 | 8 , 847 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 34 , 000 | 8 , 703 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |\\r\\n| | | |\\r\\n| 36 , 000 | 8 , 549 | 24 hours |\\r\\n| | | |\\r\\n| - - - - - - - - + - - - - - - - - - - + - - - - - - - - - - - |'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample e-mail data\n",
    "hamdata[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Format and label e-mails spam/ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_emails = ([(ham_mail.split(), 'ham') for ham_mail in hamdata] +\n",
    "                  [(spam_mail.split(), 'spam') for spam_mail in spamdata])\n",
    "import random\n",
    "random.shuffle(labeled_emails)\n",
    "\n",
    "all_emails = [email for email, classification in labeled_emails][:500]\n",
    "flattened_emails = [word for email in all_emails for word in email]\n",
    "\n",
    "tokenized_emails = []\n",
    "for word in flattened_emails:\n",
    "        tokenized_emails.extend(nltk.word_tokenize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Define feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "#extract the 500 most common words\n",
    "word_freq = nltk.FreqDist(tokenized_emails)\n",
    "top_words = [w for (w,c) in word_freq.most_common(500)]\n",
    "top_words = [w for w in top_words if w.isalpha()]\n",
    "top_words = [w for w in top_words if w not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'-', 7721),\n",
       " (u'.', 5159),\n",
       " (u',', 3787),\n",
       " (u'/', 3321),\n",
       " (u':', 2745),\n",
       " (u'the', 2583),\n",
       " (u'to', 2025),\n",
       " (u'and', 1366),\n",
       " (u'ect', 1120),\n",
       " (u'of', 1051),\n",
       " (u'a', 1041),\n",
       " (u'for', 1037),\n",
       " (u'?', 931),\n",
       " (u'@', 922),\n",
       " (u'in', 816),\n",
       " (u'on', 791),\n",
       " (u'you', 780),\n",
       " (u'this', 735),\n",
       " (u'is', 700),\n",
       " (u'i', 641)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#most common words\n",
    "print display(word_freq.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build feature extractor; uses both most common words and extremes in email length\n",
    "\n",
    "import math\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    if len(document) < 20:\n",
    "        short_mail = True\n",
    "        long_mail = False\n",
    "    elif len(document) > 1500:\n",
    "        short_mail = False\n",
    "        long_mail = True\n",
    "    else:\n",
    "        short_mail = False\n",
    "        long_mail = False\n",
    "    features['len_check({})'.format(\"short_mail\")] = short_mail\n",
    "    features['len_check({})'.format(\"long_mail\")] = long_mail\n",
    "    for word in top_words:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in labeled_emails]\n",
    "train_set, dev_test_set, test_set = featuresets[:500], featuresets[500:1000], featuresets[1000:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "preds = pd.DataFrame({'spam or ham':[email for (email,classification) in dev_test_set],\n",
    "                      'observed':[classification for (email,classification) in dev_test_set],\n",
    "                      'predicted': [classifier.classify(document_features(n)) for (n,g) in labeled_emails[500:1000]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>319</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted  ham  spam\n",
       "observed            \n",
       "ham        319    46\n",
       "spam         0   135"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(preds.observed,preds.predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impressive sensitivity at the expense of some specificity; some ham is predicted as spam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[319  46]\n",
      " [  0 135]]\n",
      "('Sensitivity : ', 1.0)\n",
      "('Specificity : ', 0.873972602739726)\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix, Accuracy, sensitivity and specificity\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(preds.observed,preds.predicted)\n",
    "sensitivity1 = (float(cm[1,1])/(cm[1,1]+cm[1,0]))\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = (float(cm[0,0])/(cm[0,0]+cm[0,1]))\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n",
      "Most Informative Features\n",
      "           contains(ect) = True              ham : spam   =     29.4 : 1.0\n",
      "          contains(stop) = True             spam : ham    =     26.9 : 1.0\n",
      "      contains(attached) = True              ham : spam   =     21.9 : 1.0\n",
      "     contains(microsoft) = True             spam : ham    =     20.7 : 1.0\n",
      "           contains(gas) = True              ham : spam   =     14.3 : 1.0\n",
      "          contains(corp) = True              ham : spam   =     13.8 : 1.0\n",
      "        contains(prices) = True             spam : ham    =     13.4 : 1.0\n",
      "             contains(j) = True              ham : spam   =     11.4 : 1.0\n",
      "          contains(deal) = True              ham : spam   =     11.0 : 1.0\n",
      "         contains(daily) = True              ham : spam   =     10.9 : 1.0\n",
      "      contains(products) = True             spam : ham    =     10.6 : 1.0\n",
      "      contains(software) = True             spam : ham    =      9.7 : 1.0\n",
      "         contains(stock) = True             spam : ham    =      9.7 : 1.0\n",
      "          contains(save) = True             spam : ham    =      8.4 : 1.0\n",
      "          contains(file) = True              ham : spam   =      8.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print 'Accuracy: %4.2f' %nltk.classify.accuracy(classifier, dev_test_set)\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for (doc, tag) in labeled_emails[500:1000]:\n",
    "    guess = classifier.classify(document_features(doc))\n",
    "    accuracy = classifier.prob_classify(document_features(doc))\n",
    "    if guess != tag:\n",
    "        errors.append( (tag, guess, len(doc), accuracy.prob(\"spam\")) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unclear, based on current analysis, what is causing the misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>guess</th>\n",
       "      <th>length</th>\n",
       "      <th>spam probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>130</td>\n",
       "      <td>0.626272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>12</td>\n",
       "      <td>0.999444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>578</td>\n",
       "      <td>0.679953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>20</td>\n",
       "      <td>0.838354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>31</td>\n",
       "      <td>0.993640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>409</td>\n",
       "      <td>0.999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>30</td>\n",
       "      <td>0.991248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>11</td>\n",
       "      <td>0.967119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>98</td>\n",
       "      <td>0.997005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>16</td>\n",
       "      <td>0.555120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>13</td>\n",
       "      <td>0.987932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>54</td>\n",
       "      <td>0.711104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>850</td>\n",
       "      <td>0.999923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>222</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>23</td>\n",
       "      <td>0.995463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>475</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>54</td>\n",
       "      <td>0.999803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>67</td>\n",
       "      <td>0.982503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>315</td>\n",
       "      <td>0.999585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>305</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>20</td>\n",
       "      <td>0.985109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>15</td>\n",
       "      <td>0.824250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>324</td>\n",
       "      <td>0.999926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>9</td>\n",
       "      <td>0.751021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>40</td>\n",
       "      <td>0.919739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>204</td>\n",
       "      <td>0.990294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>9</td>\n",
       "      <td>0.998476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>17</td>\n",
       "      <td>0.999454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>87</td>\n",
       "      <td>0.603169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>29</td>\n",
       "      <td>0.995626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>56</td>\n",
       "      <td>0.832956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>33</td>\n",
       "      <td>0.723351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>58</td>\n",
       "      <td>0.952281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>29</td>\n",
       "      <td>0.877785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>11</td>\n",
       "      <td>0.997883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>20</td>\n",
       "      <td>0.993542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>152</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>120</td>\n",
       "      <td>0.984038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>18</td>\n",
       "      <td>0.999545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>25</td>\n",
       "      <td>0.881124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>105</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>276</td>\n",
       "      <td>0.956251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>24</td>\n",
       "      <td>0.674357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>26</td>\n",
       "      <td>0.999962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>510</td>\n",
       "      <td>0.998795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tag guess  length  spam probability\n",
       "0   ham  spam     130          0.626272\n",
       "1   ham  spam      12          0.999444\n",
       "2   ham  spam     578          0.679953\n",
       "3   ham  spam      20          0.838354\n",
       "4   ham  spam      31          0.993640\n",
       "5   ham  spam     409          0.999982\n",
       "6   ham  spam      30          0.991248\n",
       "7   ham  spam      11          0.967119\n",
       "8   ham  spam      98          0.997005\n",
       "9   ham  spam      16          0.555120\n",
       "10  ham  spam      13          0.987932\n",
       "11  ham  spam      54          0.711104\n",
       "12  ham  spam     850          0.999923\n",
       "13  ham  spam     222          0.999990\n",
       "14  ham  spam      23          0.995463\n",
       "15  ham  spam     475          1.000000\n",
       "16  ham  spam      54          0.999803\n",
       "17  ham  spam      67          0.982503\n",
       "18  ham  spam     315          0.999585\n",
       "19  ham  spam     305          0.999983\n",
       "20  ham  spam      20          0.985109\n",
       "21  ham  spam       8          0.999345\n",
       "22  ham  spam      15          0.824250\n",
       "23  ham  spam     324          0.999926\n",
       "24  ham  spam       9          0.751021\n",
       "25  ham  spam      40          0.919739\n",
       "26  ham  spam     204          0.990294\n",
       "27  ham  spam       9          0.998476\n",
       "28  ham  spam      17          0.999454\n",
       "29  ham  spam      87          0.603169\n",
       "30  ham  spam      29          0.995626\n",
       "31  ham  spam      56          0.832956\n",
       "32  ham  spam      33          0.723351\n",
       "33  ham  spam      58          0.952281\n",
       "34  ham  spam      29          0.877785\n",
       "35  ham  spam      11          0.997883\n",
       "36  ham  spam      20          0.993542\n",
       "37  ham  spam     152          0.999997\n",
       "38  ham  spam     120          0.984038\n",
       "39  ham  spam      18          0.999545\n",
       "40  ham  spam      25          0.881124\n",
       "41  ham  spam     105          1.000000\n",
       "42  ham  spam     276          0.956251\n",
       "43  ham  spam      24          0.674357\n",
       "44  ham  spam      26          0.999962\n",
       "45  ham  spam     510          0.998795"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['tag', 'guess', 'length', 'modeled spam probability']\n",
    "pd.DataFrame(errors, columns = col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n",
      "Most Informative Features\n",
      "           contains(ect) = True              ham : spam   =     29.4 : 1.0\n",
      "          contains(stop) = True             spam : ham    =     26.9 : 1.0\n",
      "      contains(attached) = True              ham : spam   =     21.9 : 1.0\n",
      "     contains(microsoft) = True             spam : ham    =     20.7 : 1.0\n",
      "           contains(gas) = True              ham : spam   =     14.3 : 1.0\n",
      "          contains(corp) = True              ham : spam   =     13.8 : 1.0\n",
      "        contains(prices) = True             spam : ham    =     13.4 : 1.0\n",
      "             contains(j) = True              ham : spam   =     11.4 : 1.0\n",
      "          contains(deal) = True              ham : spam   =     11.0 : 1.0\n",
      "         contains(daily) = True              ham : spam   =     10.9 : 1.0\n",
      "      contains(products) = True             spam : ham    =     10.6 : 1.0\n",
      "      contains(software) = True             spam : ham    =      9.7 : 1.0\n",
      "         contains(stock) = True             spam : ham    =      9.7 : 1.0\n",
      "          contains(save) = True             spam : ham    =      8.4 : 1.0\n",
      "          contains(file) = True              ham : spam   =      8.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print 'Accuracy: %4.2f' %nltk.classify.accuracy(classifier, test_set)\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>2555</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>4</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted   ham  spam\n",
       "observed             \n",
       "ham        2555   403\n",
       "spam          4  1210"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf = pd.DataFrame({'spam or ham':[email for (email,classification) in test_set],\n",
    "                      'observed':[classification for (email,classification) in test_set],\n",
    "                      'predicted': [classifier.classify(document_features(n)) for (n,g) in labeled_emails[1000:]]})\n",
    "pd.crosstab(perf.observed,perf.predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that sensitivity remains very high, but some ham is unfortunately classified as spam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sensitivity : ', 0.9967051070840197)\n",
      "('Specificity : ', 0.8637592968221771)\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix, Accuracy, sensitivity and specificity\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(perf.observed,perf.predicted)\n",
    "sensitivity1 = (float(cm[1,1])/(cm[1,1]+cm[1,0]))\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = (float(cm[0,0])/(cm[0,0]+cm[0,1]))\n",
    "print('Specificity : ', specificity1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
